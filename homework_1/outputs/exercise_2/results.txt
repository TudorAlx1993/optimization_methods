My implementations:
	* method=newton_constant_step
		* convergence after no_iterations=9
		* x_star=[-0.2720017  -0.3019715  -0.30397856 -0.28994255 -0.27580233 -0.30034445
 -0.26729837 -0.29573617 -0.30543803 -0.27376158 -0.24741387 -0.28375916
 -0.2809302  -0.30515298 -0.31862207 -0.29562124 -0.28436113 -0.28792117
 -0.31452801 -0.29723611 -0.29007068 -0.28214105 -0.3245711  -0.24690491
 -0.2961997  -0.29066885 -0.30458195 -0.2881418  -0.28323349 -0.26393552
 -0.30757717 -0.30074533 -0.28869079 -0.31289174 -0.26731852 -0.29787366
 -0.29853146 -0.30269961 -0.2761435  -0.31202722 -0.28813779 -0.28317301
 -0.25922542 -0.2993561  -0.27477299 -0.26868092 -0.27430317 -0.28999926
 -0.2848534  -0.26811543]
		* gradient norm of f(x_star)=7.327966623263194e-10
		* objective function in x_star=-271.5277234101104
	* implementation with cvxpy
		* x_star=[-0.27200182 -0.30197159 -0.30397863 -0.28994265 -0.27580246 -0.30034454
 -0.26729849 -0.29573627 -0.3054381  -0.27376169 -0.24741397 -0.28375928
 -0.28093032 -0.30515306 -0.31862211 -0.29562134 -0.28436124 -0.28792128
 -0.31452806 -0.29723621 -0.29007077 -0.28214117 -0.32457114 -0.24690501
 -0.29619979 -0.29066895 -0.30458203 -0.2881419  -0.28323359 -0.26393566
 -0.30757724 -0.30074541 -0.28869089 -0.31289179 -0.26731866 -0.29787376
 -0.29853156 -0.30269969 -0.27614362 -0.31202728 -0.28813789 -0.28317312
 -0.25922553 -0.29935619 -0.2747731  -0.26868105 -0.2743033  -0.28999936
 -0.28485352 -0.26811556]
		* gradient norm of f(x_star)=2.9219304403671323e-06
		* objective function in x_star=-271.52772341010933
