My implementations:
	* method=newton_constant_step
		* convergence after no_iterations=10
		* x_star=[-0.27327144 -0.26440246 -0.2878246  -0.28116558 -0.27378689 -0.27733889
 -0.24111791 -0.29454506 -0.27959061 -0.27421723 -0.31158789 -0.29853616
 -0.26127313 -0.29863151 -0.26590268 -0.29259427 -0.28514031 -0.28110349
 -0.28442563 -0.29954112 -0.27706918 -0.29144885 -0.27029175 -0.26548748
 -0.29088827 -0.3237835  -0.25623146 -0.24443779 -0.29513016 -0.2864125
 -0.2740957  -0.27300499 -0.26704028 -0.2881461  -0.26303704 -0.30276959
 -0.27338117 -0.31219821 -0.2775274  -0.28300905 -0.2526483  -0.25761054
 -0.28204089 -0.28521524 -0.27286076 -0.27808268 -0.29317423 -0.25890303
 -0.26958124 -0.29976329]
		* gradient norm of f(x_star)=6.796218513035427e-10
		* objective function in x_star=-274.53621537024736
	* implementation with cvxpy
		* x_star=[-0.27327148 -0.26440247 -0.28782465 -0.28116563 -0.27378694 -0.27733894
 -0.24111799 -0.29454509 -0.27959065 -0.27421728 -0.31158791 -0.29853617
 -0.2612732  -0.29863153 -0.26590272 -0.29259429 -0.28514034 -0.28110352
 -0.28442566 -0.29954115 -0.27706922 -0.29144889 -0.27029182 -0.26548755
 -0.2908883  -0.32378354 -0.25623153 -0.2444379  -0.29513017 -0.28641255
 -0.27409573 -0.27300507 -0.26704033 -0.28814613 -0.26303705 -0.30276961
 -0.27338123 -0.31219824 -0.27752745 -0.28300908 -0.25264833 -0.25761059
 -0.28204093 -0.28521528 -0.27286079 -0.27808271 -0.29317426 -0.2589031
 -0.26958129 -0.29976331]
		* gradient norm of f(x_star)=1.2564288335374384e-06
		* objective function in x_star=-274.5362153702472
