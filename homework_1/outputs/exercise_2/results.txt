My implementations:
	* method=newton_constant_step
		* convergence after no_iterations=9
		* x_star=[-0.28328729 -0.31916568 -0.27991586 -0.2827783  -0.26192254 -0.28018352
 -0.29574924 -0.30190127 -0.30482903 -0.31747527 -0.29859142 -0.26889318
 -0.2830189  -0.30599784 -0.32915708 -0.3132182  -0.2751359  -0.30463241
 -0.31369625 -0.287599   -0.27159531 -0.28173313 -0.30136844 -0.31218886
 -0.29869752 -0.29915904 -0.33785673 -0.29485256 -0.28462298 -0.29588547
 -0.29950423 -0.27162343 -0.29930909 -0.28511127 -0.3012008  -0.286285
 -0.30061441 -0.29716176 -0.31669664 -0.28271193 -0.26214862 -0.32982692
 -0.30322562 -0.29333635 -0.29528369 -0.26369772 -0.32033796 -0.26195081
 -0.29270893 -0.2867335 ]
		* gradient norm of f(x_star)=4.2346567725184445e-07
		* objective function in x_star=-270.4045004858166
	* implementation with cvxpy
		* x_star=[-0.2832881  -0.31915857 -0.27991792 -0.28275319 -0.26192116 -0.28018431
 -0.29574457 -0.30189497 -0.30482622 -0.31746707 -0.29859776 -0.26888232
 -0.2830218  -0.30599742 -0.32915679 -0.31321393 -0.27513417 -0.30462934
 -0.31369668 -0.28758765 -0.27158785 -0.28173598 -0.30136723 -0.31216342
 -0.29869214 -0.29916671 -0.33784996 -0.29484013 -0.28462078 -0.29588272
 -0.29950125 -0.27162489 -0.2992997  -0.28511827 -0.30120232 -0.28628652
 -0.30060446 -0.29715838 -0.31669655 -0.28271499 -0.26214639 -0.32982492
 -0.30321943 -0.29333474 -0.2952772  -0.26369885 -0.32035157 -0.26194834
 -0.29270471 -0.28672373]
		* gradient norm of f(x_star)=0.0001994032646527295
		* objective function in x_star=-270.40450048051576
