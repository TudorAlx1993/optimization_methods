My implementations:
	* method=constant_step
		* convergence after no_iterations=420
		* x_star=[ 0.01396734  0.00237023  0.19721901 -0.30166604  0.04891729 -0.24488664
 -0.05582076 -0.27919604  0.05471949  0.04189208  0.1343811   0.01467602
 -0.18966414  0.09824523 -0.28813275 -0.03850399 -0.22815345  0.21078254
  0.01203228  0.18016587  0.29183768  0.37674296  0.13838928  0.27901972
 -0.08685263  0.25508537  0.36956873 -0.25237448 -0.17203396  0.15184509
  0.12618405  0.20472031 -0.1963099   0.1616878  -0.52549898  0.22972234
 -0.33153611  0.24135635 -0.21666869 -0.02842474 -0.05016948  0.0147623
 -0.5805605   0.13276132 -0.16004638 -0.01992095 -0.28214602 -0.08361049
  0.06558675 -0.03836581]
		* gradient norm of f(x_star)=9.911888025361367e-06
		* objective function in x_star=7.6597194365040835
	* method=ideal_step
		* convergence after no_iterations=411
		* x_star=[ 0.01396733  0.00237023  0.19721901 -0.30166604  0.04891729 -0.24488663
 -0.05582076 -0.27919604  0.0547195   0.04189208  0.1343811   0.01467602
 -0.18966415  0.09824523 -0.28813275 -0.03850399 -0.22815344  0.21078254
  0.01203229  0.18016587  0.29183768  0.37674296  0.13838928  0.27901971
 -0.08685263  0.25508537  0.36956872 -0.25237448 -0.17203396  0.15184509
  0.12618405  0.20472031 -0.1963099   0.1616878  -0.52549898  0.22972234
 -0.33153611  0.24135635 -0.21666869 -0.02842475 -0.05016947  0.01476231
 -0.5805605   0.13276132 -0.16004638 -0.01992094 -0.28214602 -0.08361049
  0.06558675 -0.03836581]
		* gradient norm of f(x_star)=9.833387241893737e-06
		* objective function in x_star=7.659719436503859
	* method=adaptive_step
		* convergence after no_iterations=141
		* x_star=[ 0.01396673  0.00237053  0.19721862 -0.30166627  0.04891645 -0.24488623
 -0.05582062 -0.27919587  0.05472013  0.04189288  0.13438044  0.01467598
 -0.18966454  0.09824519 -0.28813246 -0.03850397 -0.22815223  0.2107825
  0.01203307  0.18016574  0.29183731  0.37674212  0.13838926  0.27901845
 -0.08685182  0.2550849   0.36956834 -0.25237423 -0.17203383  0.15184463
  0.12618418  0.20472026 -0.1963105   0.16168721 -0.52549875  0.22972228
 -0.33153563  0.24135627 -0.21666718 -0.02842499 -0.05016929  0.01476323
 -0.5805602   0.13276161 -0.16004642 -0.01992029 -0.28214583 -0.08361109
  0.06558679 -0.03836652]
		* gradient norm of f(x_star)=8.2971761134448e-06
		* objective function in x_star=7.659719436491888
	* implementation with np.linalg.lstsq
		* x_star=[ 0.01396688  0.00237045  0.19721872 -0.30166621  0.04891667 -0.24488634
 -0.05582066 -0.27919591  0.05471996  0.04189266  0.13438062  0.01467598
 -0.18966445  0.0982452  -0.28813254 -0.03850398 -0.22815255  0.21078251
  0.01203286  0.18016577  0.2918374   0.37674234  0.13838928  0.27901878
 -0.08685203  0.25508502  0.36956844 -0.2523743  -0.17203386  0.15184476
  0.12618415  0.20472028 -0.19631034  0.16168737 -0.52549881  0.22972229
 -0.33153575  0.24135629 -0.21666759 -0.02842493 -0.05016934  0.01476299
 -0.58056028  0.13276153 -0.16004641 -0.01992046 -0.28214587 -0.08361093
  0.06558677 -0.03836633]
		* gradient norm of f(x_star)=1.4242224748670354e-13
		* objective function in x_star=7.6597194364899375
