My implementations:
	* method=constant_step
		* convergence after no_iterations=550
		* x_star=[ 0.19664511 -0.14160123 -0.06839657 -0.14071729 -0.70519975 -0.49000627
 -0.62397737 -0.08892385  0.16641614  0.08997872  0.23659016  0.30344899
  0.03461951 -0.23305941 -0.04005796  0.33230399  0.14902601 -0.13592386
  0.37353044 -0.05206306 -0.22985247 -0.41497818 -0.31691832 -0.16058595
  0.31688734 -0.43729535 -0.10778476 -0.0578707  -0.32391162  0.34134857
 -0.07555447  0.16342766  0.19942069  0.04790222  0.09054077 -0.37882754
  0.10283822  0.2109574  -0.13020215  0.10058954 -0.46662024 -0.09046488
  0.07117785 -0.03888458 -0.00573384 -0.22996547  0.80725234 -0.11149083
 -0.0453327  -0.24568244]
		* gradient norm of f(x_star)=9.960480410199473e-06
		* objective function in x_star=12.289991685624878
	* method=ideal_step
		* convergence after no_iterations=518
		* x_star=[ 0.19664511 -0.14160123 -0.06839657 -0.14071729 -0.70519975 -0.49000627
 -0.62397737 -0.08892385  0.16641614  0.08997872  0.23659016  0.30344899
  0.0346195  -0.23305941 -0.04005796  0.332304    0.14902601 -0.13592386
  0.37353044 -0.05206306 -0.22985247 -0.41497819 -0.31691832 -0.16058595
  0.31688735 -0.43729535 -0.10778476 -0.0578707  -0.32391162  0.34134857
 -0.07555447  0.16342766  0.19942069  0.04790223  0.09054077 -0.37882754
  0.10283822  0.2109574  -0.13020215  0.10058954 -0.46662024 -0.09046487
  0.07117786 -0.03888458 -0.00573384 -0.22996547  0.80725234 -0.11149083
 -0.0453327  -0.24568244]
		* gradient norm of f(x_star)=9.903750918337444e-06
		* objective function in x_star=12.289991685624694
	* method=adaptive_step
		* convergence after no_iterations=213
		* x_star=[ 0.19664531 -0.14160113 -0.06839648 -0.1407172  -0.70519976 -0.49000655
 -0.62397745 -0.08892398  0.16641615  0.08997863  0.23659028  0.30344897
  0.03461929 -0.23305923 -0.04005809  0.3323042   0.14902601 -0.13592375
  0.37353048 -0.05206299 -0.22985273 -0.41497846 -0.31691851 -0.16058598
  0.31688766 -0.43729572 -0.10778465 -0.05787073 -0.32391165  0.3413487
 -0.07555453  0.16342773  0.19942046  0.04790244  0.09054079 -0.37882772
  0.10283859  0.21095749 -0.13020212  0.10058952 -0.46662041 -0.09046475
  0.07117799 -0.03888458 -0.00573396 -0.22996541  0.80725249 -0.11149079
 -0.04533272 -0.2456825 ]
		* gradient norm of f(x_star)=7.222527760009735e-06
		* objective function in x_star=12.289991685616116
	* implementation with np.linalg.lstsq
		* x_star=[ 0.19664559 -0.14160085 -0.06839623 -0.14071716 -0.70519979 -0.49000695
 -0.62397749 -0.08892429  0.16641632  0.08997836  0.23659059  0.30344886
  0.03461891 -0.23305894 -0.04005844  0.33230473  0.14902591 -0.13592355
  0.37353044 -0.05206294 -0.22985321 -0.41497887 -0.31691864 -0.16058605
  0.31688834 -0.43729624 -0.10778452 -0.05787088 -0.3239117   0.34134892
 -0.07555477  0.16342782  0.19941991  0.04790301  0.0905409  -0.37882818
  0.10283943  0.21095773 -0.13020208  0.10058941 -0.46662068 -0.09046445
  0.0711783  -0.03888482 -0.00573412 -0.22996554  0.80725286 -0.11149112
 -0.04533274 -0.24568237]
		* gradient norm of f(x_star)=2.0556447906116806e-13
		* objective function in x_star=12.289991685608616
